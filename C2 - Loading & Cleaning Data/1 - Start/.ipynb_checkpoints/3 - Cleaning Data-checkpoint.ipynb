{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cf071c7",
   "metadata": {},
   "source": [
    "# Cleaning Data\n",
    "\n",
    "We can use Pandas to clean our data so that it is ready for analysis. Three different types of data issues that we will deal with are:\n",
    "1. Missing Data\n",
    "2. Duplicate Data\n",
    "3. Incorrect Data\n",
    "\n",
    "To take care of these data issues, we are able to use built in pandas functions to clean it efficiently. Before starting to clean the above, we can use the `info()` function to give us a snapshot of the type of data that is in our DataFrame and systematically change data into proper data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ada649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33e339ae",
   "metadata": {},
   "source": [
    "We can first start by seeing that the `Date` column is an `object` type, whereas the correct type for a date is `datetime`. We can correct this by inputting the follow code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e8add6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e579f1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to make a change to the DataFrame, the changes must be reinstatiated to overwrite with the changes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9488b8e",
   "metadata": {},
   "source": [
    "## Missing Data\n",
    "\n",
    "We can also see that from the `info()` function, there are null values in our data from looking at the Non-Null Count column. We can see some columns have a different non-null count, which means that these columns have more null values. To see in greater detail which columns and rows have null values, we can use the `isna()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a50606",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3c4a15b",
   "metadata": {},
   "source": [
    "This output can be difficult to interpret and action. A way to simplify this information is to pair `isna()` with the `sum()` function. Now, we can see the number of null values per each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d005a859",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a050e07",
   "metadata": {},
   "source": [
    "We will look at two different ways to deal with missing data:\n",
    "\n",
    " 1. Removing null values from DataFrame rows and/or columns\n",
    " 2. Filling null values with a constant or other values from the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b301e50e",
   "metadata": {},
   "source": [
    "### Removing null values\n",
    "\n",
    "To remove columns or rows that contain null values, we can use the `dropna()` function. We can start by dropping the rows where at least one element is null in the row. This reduces our DataFrame from 1887 rows to 1684 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc7c740",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5a0d6b3",
   "metadata": {},
   "source": [
    "We can confirm that rows have been dropped, as the number of rows compared to the initial DataFrame has decreased. We can also drop columns that have null values rather than rows with the same function, but specifying the axis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bc18f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b07c6096",
   "metadata": {},
   "source": [
    "We see that the columns that have any null values have been dropped. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021cc407",
   "metadata": {},
   "source": [
    "### Filling null values\n",
    "\n",
    "However, completely dropping columns and rows that have null values is usually not an efficient method of cleaning data, as lots of data can be lost. \n",
    "\n",
    "A more common approach to cleaning these null values is to fill them in using the `fillna()` function. Two popular uses of the function is:\n",
    "\n",
    " 1. Fill the null values with 0 or any value\n",
    " 2. Fill the null values based on the next/previous number\n",
    " \n",
    "With these methods, we can still retain valuable data and not drop the entire column/row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7157c738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling NaNs with 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c181e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling NaNs that is equal to the previous non-NaN number \"Forward Fill\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee65ab62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling NaNs that is equal to the next non-NaN number \"Back Fill\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5e28a3",
   "metadata": {},
   "source": [
    "## Duplicate Data\n",
    "\n",
    "Another data issue that we will solve in this example is to remove duplicate rows from the DataFrame. To idenfity the distinct values in a particular column, we can use the `unique()` function. This will return an array of all the unique column values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4089ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "869b1c9c",
   "metadata": {},
   "source": [
    "Rather than go through each column in the DataFrame to see all the unique values, we can return a count of unique values for each column in the DataFrame using the `nunique()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1674d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b41256b",
   "metadata": {},
   "source": [
    "Removing duplicate values can be achieved by using the `drop_duplicates` function. Using `drop_duplicates` can be a very efficient way to clean data, especially if no data is supposed to be duplicated. You must be careful when using this function however, as some data is meant to be duplicated on purpose based on the need of the business/situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1128008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by default it will drop based on if there is a duplicate for all column values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11615a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping rows based on specific column values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53577136",
   "metadata": {},
   "source": [
    "## Error Data\n",
    "\n",
    "Another common cleaning method is to identify and clean errors in our dataset. Consider the first few lines of the DataFrame in the `ProductID` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc24710",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataframe_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd921ce7",
   "metadata": {},
   "source": [
    "We can see that in the `ProductID` column, that some values have a suffix starting with `-`, which denotes that this product falls under a special category, whereas the ones without are regular products. However, the information that indicates that it is a special item should be in a different column, separated from the Product ID.\n",
    "\n",
    "To do this, we can use the `str.split()` function to slice and separate values based on the values before and after the delimiter. The delimter in this instance would be `-`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0b1796",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Note - Without instantiating the function to the actual columns, no change is made on the actual DataFrame \n",
    "dataframe_3['ProductID'].str.split('-',expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2c5fa6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Instantiating the result above to the the DataFrame. Column 0 replaces 'ProductID', column 1 replaces 'SpecialID'.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bb0c05",
   "metadata": {},
   "source": [
    "## Export Data\n",
    "\n",
    "Pandas can also export the data once we have finished cleaning it. We can use the `to_csv()` function to do so, and the file will be stored in the same directory as where this notebook is in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8ca70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_3.to_csv('export.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
