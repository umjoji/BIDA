{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a89d7b10",
   "metadata": {},
   "source": [
    "# Transforming Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4ad2fa",
   "metadata": {},
   "source": [
    "Now that we have covered the loading and cleaning of data, we will dive into how we can transform our DataFrames to discover powerful insights and relevant information. We can transform our data based on what type of insights we want to discover and our objectives. \n",
    "\n",
    "To start off the lesson we will import the relevant packages, then we will be using the `read.csv()` function to import our data as a DataFrame. For this lesson, we will be importing data of student grades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fa506b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11bbe68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d708ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f15d252c",
   "metadata": {},
   "source": [
    "## Selecting Columns and Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0a106d",
   "metadata": {},
   "source": [
    "To select a specific column, simply put the name of the column after the DataFrame in square brackets in quotation. We will see that pandas will output this column as a Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177b5fa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "437f0814",
   "metadata": {},
   "source": [
    "If there was a scenario where the StudentID along with the grade of the student is to be shown, multiple columns can be shown by submitting a list of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43015be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1de39258",
   "metadata": {},
   "source": [
    "One simple way of getting the first few rows or the last few rows of the dataset is the use the `head()` and `tail()` function. \n",
    "\n",
    "`head()` populates the first 5 rows of the DataFrame, whereas `tail()` populates the last 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689dede0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade2ceae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First 5 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbd00cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last 5 rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108971b3",
   "metadata": {},
   "source": [
    "## loc() & iloc()\n",
    "Another more scalable alternative in selecting columns is the use of `loc()` and `iloc()` functions. \n",
    "\n",
    "`loc()` is label-based, which means that we still have to specify the name of the rows and columns by their labels.\n",
    "\n",
    "`iloc()` is integer-based, which means that you will have to specify the rows and columns by their index.\n",
    "\n",
    "loc[row_label, column_label]\n",
    "\n",
    "iloc[row_position, column_position]\n",
    "\n",
    "Instead of selecting columns/rows you want, these functions will allow you to select columns/rows between or up to a certain column/row name/position.\n",
    "\n",
    "When using these functions, the `:` symbol means choose all columns/rows in between the left and right of the symbol. If there is no value on either side of the symbol, it means choose all columns/rows.\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60ce416",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Selecting all rows, with only specified columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d5356a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using iloc function, selecting all rows, with only specified columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62c5e2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Selecting all rows, with all columns in order from StudentID to Grade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89199dce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Selecting all rows, with columns in order from StudentID to Grade\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e56b01",
   "metadata": {},
   "source": [
    "We can also use the `loc()` and `iloc()` functions to select rows as well as columns. In `df_grades`, the DataFrame row index is numeric. In this instance, because the index names are a number, we can use a numeric argument in the `loc()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75c3f0e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Selecting rows based on index name, with all columns present\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf92789",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Selecting rows based on index, with all columns present\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d614c41d",
   "metadata": {},
   "source": [
    "One key note is that when using `loc`, the value after the `:` is included in the result, whereas the `iloc` does not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e81bbc7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Selecting rows in between based on index name, with all columns present\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120b5ea5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Selecting rows in between based on index, with all columns present\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650cfdbe",
   "metadata": {},
   "source": [
    "## Conditional Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779119de",
   "metadata": {},
   "source": [
    "Suppose that we want to filter the data based on specific conditions, such as students who have an outstanding tuition amount of over 40,000 or only students that are in the arts faculty. With conditional statements, we can filter the data to find specific information and insights. \n",
    "\n",
    "To write a conditional statement, we will have to write a boolean statement that classifies each value as `True` or `False`, then pandas will then filter for the values that are `True` that match the logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36931a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pandas reads all instances where the row is either True or False, then this logic is inputted to the dataframe condition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08a1d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65fac24",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Tuition amount of at least 40k\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65486971",
   "metadata": {},
   "source": [
    "Suppose we want information on only one faculty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80bc6ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Students that are in the arts faculty\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2990915b",
   "metadata": {},
   "source": [
    "Multiple conditions can be inputted as well. Suppose we want to see student information that skipped at least 3 classes and have participated in 5 or more office hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9146aff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Students that skipped at least 3 classes and participated in at least 5 hours of office hours\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe8d520",
   "metadata": {},
   "source": [
    "## Adding/Removing Columns and Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360f0f62",
   "metadata": {},
   "source": [
    "To add new columns to our DataFrame, we can simply declare a new list as a column. Consider a scenario where we want to update our student data with the corresponding cities of the students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74990b2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Keep in mind, the length of the list has to match the length of index of the DataFrame\n",
    "city = ['Vancouver','Toronto','Calgary','Edmonton','Regina', 'Burnaby', 'Coquitlam', 'London', 'Ottawa', 'Texas',\n",
    "       'Coquitlam', 'London', 'Ottawa', 'Texas','Edmonton','Regina', 'Burnaby', 'Coquitlam', 'London', 'Ottawa', \n",
    "        'Texas', 'Toronto','Calgary','Edmonton','Regina', 'Burnaby', 'Coquitlam', 'London',  'Texas','Edmonton'\n",
    "       ]\n",
    "\n",
    "df_grades['City'] = city\n",
    "df_grades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d3b698",
   "metadata": {},
   "source": [
    "Another method of adding new columns is to use the `insert()` function. This function allows us to add the column in any position we like and not only the end. Consider a scenario where now we want to add the age of students in our data, and want to see it before their name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22c053e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Adding a new column in index 1 (2nd column)\n",
    "\n",
    "df_grades.insert(1, \"Age\", [21, 23, 24, 21, 25, 18, 22, 25, 28, 34, \n",
    "                     22, 23, 25, 21, 25, 26, 24, 23, 29, 31, \n",
    "                     28, 24, 24, 23, 22, 20, 23, 25, 28, 33 \n",
    "                    ])\n",
    "df_grades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfe9b1d",
   "metadata": {},
   "source": [
    "While this is uncommmon, we can add new rows to the DataFrame as well.\n",
    "\n",
    "Let's consider a scenario where there is a new student that needs to be submitted to the system. \n",
    "\n",
    "To add new rows, we will have to create a new DataFrame with the data we want to add then use the `append()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6910036",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_student = {'StudentID': 20123420, 'Age':21, 'FirstName': 'Scottie', 'LastName': 'Barnes', 'GradeAverage': 'A', \n",
    "               'Faculty': 'Science', 'Tuition': 50000,'OfficeHoursParticipated': 0, 'ClassesSkipped': 0, 'City': 'Toronto'}\n",
    "\n",
    "df2 = pd.DataFrame(data=new_student, index=[30])\n",
    "\n",
    "df_grades = df_grades.append(df2)\n",
    "df_grades.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cf2595",
   "metadata": {},
   "source": [
    "To remove columns and rows, we can simply use the `drop()` function. If a student is no longer attending the school or find a categeory to be irrelevant, we can simply remove the data. \n",
    "\n",
    "Consider a scenario where the last person to register dropped out of school and their information is to be deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bd064d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop rows with index number\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f53e1f2",
   "metadata": {},
   "source": [
    "Anothe way of deleting rows is based on condition. Suppose that all the students in business faculty dropped out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9194af3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3345ef8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f158550",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78407003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows based on column value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9cdb45",
   "metadata": {},
   "source": [
    "We can also drop entire columns as well. Suppose that city of students is no longer a relevant information to be kept in the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202fddd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0ba141",
   "metadata": {},
   "source": [
    "## Creating New Indicies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0093a73b",
   "metadata": {},
   "source": [
    "We can modify the indicies in our DataFrame so that it is more relevant to our needs, rather than the standard numbering system. One example of this would be if we were to use our StudentIDs as our index. We can use the `set_index()` function to set this as our index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2459c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e01ef705",
   "metadata": {},
   "source": [
    "However, if we wanted to revert back to the old index, we can simply ues the `reset_index()` function to revert back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bad6a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b59d160",
   "metadata": {},
   "source": [
    "## Grouping Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c388c7e0",
   "metadata": {},
   "source": [
    "Another powerful way to derive insights from your data is the use of a `groupby()` function. This involves combining like values together to generate aggregated values associated with the combined values.\n",
    "\n",
    "Some common functions that are used after a `groupby` functions include:\n",
    "\n",
    "    1. mean\n",
    "    2. median\n",
    "    3. count\n",
    "    4. sum\n",
    "\n",
    "Consider for example we wanted to group the number of students by faculty, then count the number of students per faculty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d3799b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the count of StudentIDs, grouped by each faculty\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a01be7",
   "metadata": {},
   "source": [
    "If we wanted to find the average age by faculty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1b9e32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Selecting the mean of the ages, grouped by each faculty\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8ccf5f",
   "metadata": {},
   "source": [
    "Suppose we wanted to find the tuition spent for each faculty, broken down by grade. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae04cc7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Selecting the average age of each grade in each faculty\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100049b6",
   "metadata": {},
   "source": [
    "We can see that based on the example above, we can uncover insights that were not obvious to us previously, such as the engineering faculty having no students with an A average, no students have an F average, and their B and C average students pay the most out of all faculties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc85a02b",
   "metadata": {},
   "source": [
    "## Concatenation of DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fd2c6e",
   "metadata": {},
   "source": [
    "In a corporate environment, there will be many instances where multiple datasets will need to be combined. In this instance, the `concat()` function will allow us to combine DataFrames together into one.\n",
    "\n",
    "Suppose we have separate DataFrame of student information in another server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781be0b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data2 = {'StudentID': [20123420,20123421], 'Age':[33,31], 'FirstName': ['Stephen','Klay'], \n",
    "         'LastName': ['Curry','Thompson'], 'GradeAverage': ['A','A'], 'Faculty': ['Science','Math'], \n",
    "         'Tuition': [31000,41000], 'OfficeHoursParticipated': [3,1], 'ClassesSkipped': [4,6], \n",
    "         'State': ['California','California']}\n",
    "df_grades2 = pd.DataFrame(data2)\n",
    "df_grades2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b97457",
   "metadata": {},
   "source": [
    "In order to combine the two DataFrames together, there are two ways of concatenating:\n",
    "\n",
    "1. Concatenating the DataFrames horizontally\n",
    "2. Concatenating the DataFrames vertically\n",
    "\n",
    "We will first go through concatenating vertically. We see that the two rows in the second DataFrame have been added below the first. However in the results below we see that the `State` column was added, because the second DataFrame had this column. Therefore, the values in the first DataFrame that did not have this information will be shown as `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4884eeb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#concatentate two dataframes vertically, adding addtional rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4b7908",
   "metadata": {},
   "source": [
    "If we were to concatenate the two DataFrames horizontally, it would not look great, as we are combining datasets that have the same columns. When combining two DataFrames, we must consider if we want to add more data in the column level or row level before deciding to concatenate horizontally or vertically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27a727f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# concatenate two dataframes horizontally, adding addtional columns\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
